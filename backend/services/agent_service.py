import asyncio
import os
import json
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import uuid

from models.agent import (
    AgentMessage, AgentContext, AgentSuggestion, 
    UserInteraction, AgentResponse, AgentConfig, MessageRole
)
from models.devices import HomeState, SensorDevice, SensorType, Room
from database.database import db
from openai import OpenAI

class AgentService:
    """æ™ºèƒ½ä½“æœåŠ¡"""
    
    def __init__(self):
        self.config = AgentConfig()
        self.context = AgentContext(
            messages=[],
            current_state={},
            user_preferences={}
        )
        self.last_suggestion_time = None
        self.is_active = False
        self.llm_client = None
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        self._init_llm_client()
    
    def _init_llm_client(self):
        """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯"""
        # ä¼˜å…ˆä½¿ç”¨DashScope API
        dashscope_key = os.getenv("DASHSCOPE_API_KEY")
        if dashscope_key:
            dashscope_base_url = os.getenv("DASHSCOPE_BASE_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1")
            try:
                self.llm_client = OpenAI(
                    api_key=dashscope_key,
                    base_url=dashscope_base_url
                )
                self.config.model = os.getenv("DASHSCOPE_MODEL", "qwen-turbo")
                print(f"âœ… å·²é…ç½®DashScope API ({self.config.model})")
                return
            except Exception as e:
                raise ValueError(f"âŒ DashScopeé…ç½®å¤±è´¥: {e}")

        # å¤‡ç”¨API
        pass
 
        # æ— å¯ç”¨APIæˆ–ä½¿ç”¨æ¼”ç¤ºæ¨¡å¼
        raise ValueError("âŒ æœªé…ç½®æœ‰æ•ˆçš„LLM APIå¯†é’¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY")
    
    async def initialize(self):
        """åˆå§‹åŒ–æ™ºèƒ½ä½“æœåŠ¡ï¼ˆå¿…é¡»æœ‰LLMæ”¯æŒï¼‰"""
        if not self.llm_client:
            raise RuntimeError("âŒ LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼Œæ™ºèƒ½ä½“æœåŠ¡æ— æ³•å¯åŠ¨ã€‚è¯·æ£€æŸ¥DashScope APIé…ç½®ã€‚")
        
        # åŠ è½½å†å²æ¶ˆæ¯
        await self._load_context()
        self.is_active = True
        print("ğŸ¤– æ™ºèƒ½ä½“æœåŠ¡å·²å¯åŠ¨ï¼ˆLLMæ¨¡å¼ï¼‰")
    
    async def _load_context(self):
        """åŠ è½½å†å²ä¸Šä¸‹æ–‡"""
        # ä»æ•°æ®åº“åŠ è½½æœ€è¿‘çš„æ¶ˆæ¯
        recent_messages = db.get_recent_messages(self.config.max_context_length)
        
        self.context.messages = []
        for msg_data in recent_messages:
            message = AgentMessage(
                id=msg_data["id"],
                role=MessageRole(msg_data["role"]),
                content=msg_data["content"],
                timestamp=datetime.fromisoformat(msg_data["timestamp"]),
                metadata=json.loads(msg_data["metadata"]) if msg_data["metadata"] else {}
            )
            self.context.messages.append(message)
        
        # åŠ è½½ç”¨æˆ·åå¥½
        preferences = db.get_preference("user_preferences")
        if preferences:
            self.context.user_preferences = preferences
    
    async def analyze_home_state(self, home_state: HomeState) -> Optional[AgentSuggestion]:
        """åˆ†æå®¶å±…çŠ¶æ€å¹¶ç”Ÿæˆå»ºè®®"""
        self.context.current_state = home_state.dict()
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆå»ºè®®
        if not self._should_generate_suggestion(home_state):
            return None
        
        # åˆ†æçŠ¶æ€å¹¶ç”Ÿæˆå»ºè®®
        suggestion = await self._generate_suggestion(home_state)
        
        if suggestion and suggestion.confidence >= self.config.suggestion_threshold:
            # ä¿å­˜å»ºè®®ä¸ºæ¶ˆæ¯
            message = AgentMessage(
                id=str(uuid.uuid4()),
                role=MessageRole.AGENT,
                content=suggestion.content,
                timestamp=datetime.now(),
                metadata={
                    "suggestion_id": suggestion.id,
                    "confidence": suggestion.confidence,
                    "reasoning": suggestion.reasoning
                }
            )
            
            await self._add_message(message)
            self.last_suggestion_time = datetime.now()
            
            return suggestion
        
        return None
    
    def _should_generate_suggestion(self, home_state: HomeState) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç”Ÿæˆå»ºè®®"""
        # å¦‚æœä¸æ˜¯ä¸»åŠ¨æ¨¡å¼ï¼Œä¸ç”Ÿæˆå»ºè®®
        if not self.config.proactive_mode:
            return False
        
        # å¦‚æœæœ€è¿‘åˆšç”Ÿæˆè¿‡å»ºè®®ï¼Œé¿å…è¿‡äºé¢‘ç¹
        if (self.last_suggestion_time and 
            datetime.now() - self.last_suggestion_time < timedelta(minutes=5)):
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å€¼å¾—å…³æ³¨çš„çŠ¶æ€
        return True
    
    async def _generate_suggestion(self, home_state: HomeState) -> Optional[AgentSuggestion]:
        """ä½¿ç”¨LLMç”Ÿæˆæ™ºèƒ½å»ºè®®ï¼ˆä»…æ”¯æŒLLMï¼‰"""
        try:
            # åˆ†æå½“å‰çŠ¶æ€
            analysis = self._analyze_state_patterns(home_state)
            
            if not analysis:
                return None
            
            # æ„å»ºè¯¦ç»†çš„çŠ¶æ€æè¿°
            state_description = self._build_detailed_state_description(home_state, analysis)
            
            # æ„å»ºæç¤ºè¯
            system_prompt = self._build_system_prompt_v2()
            user_prompt = self._build_user_prompt_v2(state_description, analysis)
            
            # è°ƒç”¨LLM API
            response = await self._call_llm_api(system_prompt, user_prompt)
            
            if response:
                # è§£æAIå“åº”
                return self._parse_ai_response_v2(response, analysis)
            else:
                print("âŒ LLMè°ƒç”¨å¤±è´¥ï¼Œæ— å¯ç”¨çš„å»ºè®®ç”Ÿæˆæ–¹å¼")
                return None
                
        except Exception as e:
            print(f"âŒ AIå»ºè®®ç”Ÿæˆå¤±è´¥: {e}")
            return None
    
    async def _call_llm_api(self, system_prompt: str, user_prompt: str) -> Optional[str]:
        """è°ƒç”¨LLM API"""
        try:
            if not self.llm_client:
                return None
            
            import asyncio
            
            # ä½¿ç”¨å¼‚æ­¥æ–¹å¼è°ƒç”¨
            def sync_call():
                # ä¸ºqwenæ¨¡å‹æ·»åŠ ç‰¹æ®Šå‚æ•°
                extra_params = {}
                if "qwen" in self.config.model.lower():
                    extra_params["stream"] = False
                    extra_params["extra_body"] = {"enable_thinking": False}
                
                return self.llm_client.chat.completions.create(
                    model=self.config.model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.7,
                    max_tokens=300,
                    timeout=10,  # 10ç§’è¶…æ—¶
                    **extra_params
                )
            
            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥è°ƒç”¨
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(None, sync_call)
            
            if response and response.choices:
                return response.choices[0].message.content.strip()
            else:
                print("âŒ LLM APIè¿”å›ç©ºå“åº”")
                return None
            
        except Exception as e:
            print(f"âŒ LLM APIè°ƒç”¨å¤±è´¥: {e}")
            return None
    
    def _build_detailed_state_description(self, home_state: HomeState) -> str:
        """æ„å»ºè¯¦ç»†çš„çŠ¶æ€æè¿°"""
        descriptions = []
        
        # æˆ¿é—´å ç”¨çŠ¶æ€
        for room, occupied in home_state.room_occupancy.items():
            room_name = self._translate_room_name(room)
            if occupied:
                # æŸ¥æ‰¾åœç•™æ—¶é—´
                duration = 0
                for device in home_state.devices:
                    if (device.room == room and 
                        hasattr(device, 'sensor_type') and 
                        device.sensor_type == "motion" and
                        hasattr(device, 'detection_duration')):
                        duration = device.detection_duration
                        break
                
                if duration > 60:
                    descriptions.append(f"{room_name}æœ‰äººå·²åœç•™{duration//60}åˆ†é’Ÿ")
                else:
                    descriptions.append(f"{room_name}æœ‰äºº")
            else:
                descriptions.append(f"{room_name}æ— äºº")
        
        # è®¾å¤‡çŠ¶æ€
        device_states = []
        for device in home_state.devices:
            if device.type == "light":
                room_name = self._translate_room_name(device.room)
                status = "å¼€å¯" if device.status == "on" else "å…³é—­"
                device_states.append(f"{room_name}{device.name}{status}")
            elif device.type == "air_conditioner" and device.status == "on":
                room_name = self._translate_room_name(device.room)
                temp = getattr(device, 'temperature', 26)
                device_states.append(f"{room_name}ç©ºè°ƒå¼€å¯ï¼Œè®¾å®š{temp}Â°C")
        
        # ç»„åˆæè¿°
        state_desc = "ï¼›".join(descriptions)
        if device_states:
            state_desc += "ã€‚è®¾å¤‡çŠ¶æ€ï¼š" + "ï¼›".join(device_states)
        
        return state_desc
    
    def _build_system_prompt_v2(self) -> str:
        """æ„å»ºä¼˜åŒ–çš„ç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½å®¶å±…åŠ©æ‰‹ï¼Œè´Ÿè´£åˆ†æå®¶å±…çŠ¶æ€å¹¶æä¾›ä¸»åŠ¨å»ºè®®ã€‚

ä½ çš„èŒè´£ï¼š
1. åˆ†æå½“å‰å®¶å±…è®¾å¤‡çŠ¶æ€å’Œäººå‘˜ä½ç½®
2. è¯†åˆ«å¯èƒ½çš„é—®é¢˜ï¼šèƒ½è€—æµªè´¹ã€å®‰å…¨éšæ‚£ã€èˆ’é€‚åº¦é—®é¢˜
3. ä»¥è‡ªç„¶ã€å‹å¥½çš„è¯­æ°”æä¾›å…·ä½“å»ºè®®
4. å»ºè®®è¦å®ç”¨ä¸”å®¹æ˜“æ‰§è¡Œ

å›å¤è¦æ±‚ï¼š
- ç›´æ¥ç»™å‡ºå»ºè®®ï¼Œä¸è¦å¤šä½™çš„å®¢å¥—è¯
- ä½¿ç”¨"ä½ "è€Œä¸æ˜¯"æ‚¨"
- è¯­æ°”è¦è‡ªç„¶äº²åˆ‡ï¼Œåƒæœ‹å‹ä¸€æ ·
- ä¸€æ¬¡åªå…³æ³¨æœ€é‡è¦çš„1-2ä¸ªé—®é¢˜
- å»ºè®®è¦å…·ä½“æ˜ç¡®

ç¤ºä¾‹é£æ ¼ï¼š
"ä½ åœ¨å§å®¤å¾…äº†10åˆ†é’Ÿäº†ï¼Œå®¢å…çš„ç¯è¿˜å¼€ç€ï¼Œè¦ä¸è¦å…³æ‰èŠ‚çœç”µè´¹ï¼Ÿ"
"å¨æˆ¿æ²¡äººä½†ç¯è¿˜äº®ç€ï¼Œæˆ‘å¸®ä½ å…³æ‰å§ï¼Ÿ"
"å§å®¤æ¸©åº¦æœ‰ç‚¹é«˜ï¼Œè¦å¼€ç©ºè°ƒå—ï¼Ÿ"
"""
    
    def _build_user_prompt_v2(self, state_description: str, analysis: Dict[str, Any]) -> str:
        """æ„å»ºä¼˜åŒ–çš„ç”¨æˆ·æç¤ºè¯"""
        prompt = f"å½“å‰å®¶å±…çŠ¶æ€ï¼š{state_description}\n\n"
        
        # æ·»åŠ å‘ç°çš„é—®é¢˜
        if analysis.get("device_issues"):
            issues = []
            for issue in analysis["device_issues"]:
                if issue["type"] == "unused_light":
                    room_name = self._translate_room_name(issue["room"])
                    issues.append(f"{room_name}æ— äººä½†ç¯å¼€ç€")
            
            if issues:
                prompt += f"å‘ç°çš„é—®é¢˜ï¼š{';'.join(issues)}\n\n"
        
        # æ·»åŠ ç”¨æˆ·è¡Œä¸ºæ¨¡å¼
        if analysis.get("patterns"):
            patterns = []
            for pattern in analysis["patterns"]:
                if pattern["type"] == "long_stay":
                    room_name = self._translate_room_name(pattern["room"])
                    duration_min = pattern["duration"] // 60
                    patterns.append(f"åœ¨{room_name}åœç•™{duration_min}åˆ†é’Ÿ")
            
            if patterns:
                prompt += f"ç”¨æˆ·è¡Œä¸ºï¼š{';'.join(patterns)}\n\n"
        
        prompt += "è¯·åˆ†æè¿™ä¸ªçŠ¶æ€ï¼Œå¦‚æœå‘ç°éœ€è¦ç”¨æˆ·å…³æ³¨çš„é—®é¢˜ï¼Œç»™å‡ºä¸€ä¸ªç®€æ´å‹å¥½çš„å»ºè®®ã€‚å¦‚æœä¸€åˆ‡æ­£å¸¸ï¼Œå›å¤'å½“å‰çŠ¶æ€è‰¯å¥½'ã€‚"
        
        return prompt
    
    def _parse_ai_response_v2(self, ai_response: str, analysis: Dict[str, Any]) -> AgentSuggestion:
        """è§£æAIå“åº”"""
        # å¦‚æœAIè®¤ä¸ºä¸€åˆ‡æ­£å¸¸ï¼Œä¸ç”Ÿæˆå»ºè®®
        if "å½“å‰çŠ¶æ€è‰¯å¥½" in ai_response or "æ²¡æœ‰é—®é¢˜" in ai_response:
            return None
        
        # æ„å»ºå»ºè®®çš„æ“ä½œ
        actions = []
        confidence = 0.9  # AIå»ºè®®çš„ç½®ä¿¡åº¦è¾ƒé«˜
        
        # æ ¹æ®åˆ†æç»“æœæ¨æ–­å¯èƒ½çš„æ“ä½œ
        for issue in analysis.get("device_issues", []):
            if issue["type"] == "unused_light":
                actions.append({
                    "type": "turn_off_lights",
                    "room": issue["room"],
                    "devices": issue["devices"]
                })
        
        # å¦‚æœæ²¡æœ‰å…·ä½“æ“ä½œï¼Œé™ä½ç½®ä¿¡åº¦
        if not actions:
            confidence = 0.7
        
        return AgentSuggestion(
            id=str(uuid.uuid4()),
            content=ai_response,
            confidence=confidence,
            suggested_actions=actions,
            reasoning="åŸºäºqwenæ¨¡å‹çš„æ™ºèƒ½åˆ†æ",
            timestamp=datetime.now()
        )
    
    def _translate_room_name(self, room: str) -> str:
        """ç¿»è¯‘æˆ¿é—´åç§°"""
        room_names = {
            "living_room": "å®¢å…",
            "bedroom": "å§å®¤", 
            "kitchen": "å¨æˆ¿",
            "bathroom": "å«ç”Ÿé—´",
            "balcony": "é˜³å°"
        }
        return room_names.get(room, room)
    
    async def handle_user_interaction(self, interaction: UserInteraction) -> AgentResponse:
        """å¤„ç†ç”¨æˆ·äº¤äº’"""
        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        user_message = AgentMessage(
            id=str(uuid.uuid4()),
            role=MessageRole.USER,
            content=interaction.message,
            timestamp=datetime.now(),
            metadata=interaction.context or {}
        )
        await self._add_message(user_message)
        
        # å¤„ç†ç”¨æˆ·å›å¤
        response_content = await self._process_user_response(interaction.message)
        actions_taken = []
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰§è¡Œæ“ä½œ
        if "æ˜¯" in interaction.message or "å¥½" in interaction.message or "å¸®æˆ‘" in interaction.message:
            # æ‰§è¡Œå»ºè®®çš„æ“ä½œ
            actions_taken = await self._execute_suggested_actions()
            if actions_taken:
                response_content += " å·²ç»å¸®ä½ å®Œæˆäº†ï¼"
        elif "ä¸" in interaction.message or "ä¸ç”¨" in interaction.message:
            response_content = "å¥½çš„ï¼Œæˆ‘è®°ä½äº†ä½ çš„åå¥½ã€‚"
        
        # ä¿å­˜åŠ©æ‰‹å›å¤
        agent_message = AgentMessage(
            id=str(uuid.uuid4()),
            role=MessageRole.AGENT,
            content=response_content,
            timestamp=datetime.now(),
            metadata={"actions_taken": actions_taken}
        )
        await self._add_message(agent_message)
        
        return AgentResponse(
            message=response_content,
            suggestions=[],
            actions_taken=actions_taken,
            needs_user_confirmation=False,
            timestamp=datetime.now()
        )
    
    async def _process_user_response(self, message: str) -> str:
        """å¤„ç†ç”¨æˆ·å“åº”ï¼ˆä½¿ç”¨LLMï¼‰"""
        try:
            if not self.llm_client:
                print("âŒ LLMå®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œæ— æ³•å¤„ç†ç”¨æˆ·å“åº”")
                return "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚"
            
            # æ„å»ºç³»ç»Ÿæç¤º
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½å®¶å±…åŠ©æ‰‹ï¼Œè´Ÿè´£å›åº”ç”¨æˆ·çš„æ¶ˆæ¯ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„å›å¤ç»™å‡ºç®€æ´å‹å¥½çš„å“åº”ã€‚
å¦‚æœç”¨æˆ·åŒæ„å»ºè®®ï¼Œå›å¤ç¡®è®¤ä¿¡æ¯ã€‚
å¦‚æœç”¨æˆ·æ‹’ç»å»ºè®®ï¼Œè¡¨ç¤ºç†è§£å¹¶è®°ä½åå¥½ã€‚
ä¿æŒå›å¤ç®€æ´å‹å¥½ã€‚"""
            
            # æ„å»ºç”¨æˆ·æç¤º
            user_prompt = f"ç”¨æˆ·è¯´ï¼š{message}\n\nè¯·ç»™å‡ºåˆé€‚çš„å›å¤ï¼š"
            
            # è°ƒç”¨LLM API
            response = await self._call_llm_api(system_prompt, user_prompt)
            
            if response:
                return response
            else:
                return "æˆ‘æ˜ç™½äº†ã€‚æœ‰ä»€ä¹ˆéœ€è¦å¸®åŠ©çš„å¯ä»¥éšæ—¶å‘Šè¯‰æˆ‘ã€‚"
                
        except Exception as e:
            print(f"âŒ å¤„ç†ç”¨æˆ·å“åº”å¤±è´¥: {e}")
            return "æˆ‘æ˜ç™½äº†ã€‚æœ‰ä»€ä¹ˆéœ€è¦å¸®åŠ©çš„å¯ä»¥éšæ—¶å‘Šè¯‰æˆ‘ã€‚"
    
    async def _execute_suggested_actions(self) -> List[Dict[str, Any]]:
        """æ‰§è¡Œå»ºè®®çš„æ“ä½œ"""
        # è¿™é‡Œéœ€è¦ä¸å®¶å±…æ¨¡æ‹Ÿå™¨äº¤äº’æ‰§è¡Œå®é™…æ“ä½œ
        # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿçš„æ‰§è¡Œç»“æœ
        actions_taken = []
        
        # æŸ¥æ‰¾æœ€è¿‘çš„å»ºè®®æ¶ˆæ¯
        for message in reversed(self.context.messages):
            if (message.role == MessageRole.AGENT and 
                "suggestion_id" in message.metadata):
                # æ¨¡æ‹Ÿæ‰§è¡Œå…³ç¯æ“ä½œ
                actions_taken.append({
                    "type": "turn_off_lights",
                    "status": "success",
                    "message": "å·²å…³é—­ç›¸å…³ç¯å…‰"
                })
                break
        
        return actions_taken
    
    async def _add_message(self, message: AgentMessage):
        """æ·»åŠ æ¶ˆæ¯åˆ°ä¸Šä¸‹æ–‡"""
        self.context.messages.append(message)
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        db.save_message(message)
        
        # é™åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦
        if len(self.context.messages) > self.config.max_context_length:
            self.context.messages = self.context.messages[-self.config.max_context_length:]
        
        self.context.last_interaction = datetime.now()
    
    def get_context(self) -> AgentContext:
        """è·å–å½“å‰ä¸Šä¸‹æ–‡"""
        return self.context
    
    def is_agent_active(self) -> bool:
        """æ£€æŸ¥æ™ºèƒ½ä½“æ˜¯å¦æ´»è·ƒ"""
        return self.is_active
    
    async def get_conversation_history(self, limit: int = 20) -> List[AgentMessage]:
        """è·å–å¯¹è¯å†å²"""
        messages_data = db.get_recent_messages(limit)
        messages = []
        
        for msg_data in messages_data:
            message = AgentMessage(
                id=msg_data["id"],
                role=MessageRole(msg_data["role"]),
                content=msg_data["content"],
                timestamp=datetime.fromisoformat(msg_data["timestamp"]),
                metadata=json.loads(msg_data["metadata"]) if msg_data["metadata"] else {}
            )
            messages.append(message)
        
        return messages
